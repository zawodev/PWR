{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c6ab556",
   "metadata": {},
   "source": [
    "## Sztuczna inteligencja i inżynieria wiedzy \n",
    "### Lista 2 - Implementacja MinMax dla gry Clobber\n",
    "##### Aleksander Stepaniuk 272644\n",
    "\n",
    "Raport dokumentuje strukturę projektu, kluczowe fragmenty kodu, napotkane problemy, użyte heurystyki i wnioski."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb83b7",
   "metadata": {},
   "source": [
    "## 1. Struktura projektu\n",
    "`clobber_app/`\n",
    "- `main.py`: punkt wejścia, zbiera parametry wejściowe przez CLI lub GUI, uruchamia grę\n",
    "- `game.py`: reprezentacja stanu gry, obsługa i generowanie możliwych ruchów\n",
    "- `players.py`: definicje graczy (human, random, minimax)\n",
    "- `heuristics.py`: funkcje heurystyczne\n",
    "- `search.py`: minimax z alfa-beta\n",
    "- `utils.py`: konwersja notacji, dekorator timing, wyświetlanie\n",
    "- `logger_config.py`: kolorowany logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5328aab",
   "metadata": {},
   "source": [
    "## 2. Reprezentacja stanu gry (`game.py`)\n",
    "Poniższa klasa `GameState` reprezentuje stan gry, w tym planszę i aktualnego gracza. Zawiera metody do inicjalizacji planszy oraz możliwych operacji na planszy, takich jak generowanie możliwych ruchów czy liczenie atakowanych pionków do wykorzystania w heurystykach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6310f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameState:\n",
    "    def __init__(self, rows: int = 5, cols: int = 6):\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.board = [[None]*cols for _ in range(rows)]\n",
    "        self._init_board()\n",
    "        self.current = 'B'  # 'B' = black (first), 'W' = white (second)\n",
    "\n",
    "    def _init_board(self):\n",
    "        for r in range(self.rows):\n",
    "            for c in range(self.cols):\n",
    "                self.board[r][c] = 'B' if (r+c) % 2 == 0 else 'W'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950082c",
   "metadata": {},
   "source": [
    "## 3. Heurystyki (`heuristics.py`)\n",
    "\n",
    "Wyróżniłem cztery heurystyki:\n",
    "- **mobility**: oblicza ilość atakowanych przez gracza pionków przeciwnika i jako heurystykę zwraca jeden przez tę liczbę dla reszty z dzielenia przez dwa równą jeden oraz minus jeden przez tę liczbę dla reszty z dzielenia przez dwa równą zero\n",
    "- **opp_mobility**: 1 / (1 + liczba atakowanych naszych pionków przez oponenta)\n",
    "- **centrality**: różnica sum odwrotności odległości od środka planszy gracza i przeciwnika\n",
    "- **combined**: suma powyższych\n",
    "\n",
    "Każda heurystyka obsługuje terminalne pozycje (czyli kiedy gra się kończy zwraca +∞ lub –∞).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db5bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "INF = float('inf')\n",
    "\n",
    "def _terminal_value(state, player: str):\n",
    "    opp = 'W' if player == 'B' else 'B'\n",
    "    if state.current == player and state.is_terminal():\n",
    "        return -INF\n",
    "    if state.current == opp and state.is_terminal():\n",
    "        return INF\n",
    "\n",
    "    return None\n",
    "\n",
    "def mobility(state, player: str):\n",
    "    term = _terminal_value(state, player)\n",
    "    if term is not None:\n",
    "        return term\n",
    "\n",
    "    num = state.count_attacked_enemy_pieces(player)\n",
    "    if num == 0:\n",
    "        return -INF\n",
    "\n",
    "    if num % 2 == 1:\n",
    "        return 1.0 / num\n",
    "\n",
    "    return -(1.0 / num)\n",
    "\n",
    "def opponent_mobility(state, player: str):\n",
    "    term = _terminal_value(state, player)\n",
    "    if term is not None:\n",
    "        return term\n",
    "    opp = 'W' if player == 'B' else 'B'\n",
    "    num = state.count_attacked_enemy_pieces(opp)\n",
    "    # im mniej ruchów ma przeciwnik, tym większy wynik\n",
    "    return 1.0 / (1 + num)\n",
    "\n",
    "def centrality(state: GameState, player: str):\n",
    "    term = _terminal_value(state, player)\n",
    "    if term is not None:\n",
    "        return term\n",
    "\n",
    "    rows, cols = state.rows, state.cols\n",
    "    center_r = (rows - 1) / 2\n",
    "    center_c = (cols - 1) / 2\n",
    "    max_dist = math.hypot(center_r, center_c)\n",
    "\n",
    "    def score_for(p_char: str) -> float:\n",
    "        total = 0.0\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                if state.board[r][c] == p_char:\n",
    "                    d = math.hypot(r - center_r, c - center_c)\n",
    "                    total += (max_dist - d) / max_dist\n",
    "        return total\n",
    "\n",
    "    me = score_for(player)\n",
    "    opp = score_for('W' if player == 'B' else 'B')\n",
    "    return me - opp\n",
    "\n",
    "def combined(state: GameState, player: str) -> float:\n",
    "    term = _terminal_value(state, player)\n",
    "    if term is not None:\n",
    "        return term\n",
    "\n",
    "    return mobility(state, player) + opponent_mobility(state, player) + centrality(state, player)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb86ffc",
   "metadata": {},
   "source": [
    "## 4. Minimax z Alfa-Beta (`search.py`)\n",
    "- Implementacja rekurencyjna z funkcjami `max_value` i `min_value`\n",
    "- Przechodzimy w pętli przez wszystkie możliwe ruchy, tworząc kopię stanu gry, następnie stosujemy ruch i wywołujemy na przemiennie `max_value` i `min_value` wewnątrz siebie dopóki nie osiągniemy głębokości lub stanu końcowego\n",
    "- Funkcja zwraca najlepszy możliwy ruch oraz statystyki takie jak ilość odwiedzonych węzłów i czas wykonania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd78c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class SearchResult:\n",
    "    def __init__(self, move=None, value=None, stats=None):\n",
    "        self.move = move\n",
    "        self.value = value\n",
    "        self.stats = stats or {'nodes': 0, 'time': 0}\n",
    "\n",
    "def minimax_decision(state, depth, player, heuristic_fn, alpha_beta=False):\n",
    "    stats = {'nodes': 0}\n",
    "\n",
    "    def max_value(s, d, alpha, beta):\n",
    "        stats['nodes'] += 1\n",
    "        # implementacja max_value\n",
    "        pass\n",
    "\n",
    "    def min_value(s, d, alpha, beta):\n",
    "        stats['nodes'] += 1\n",
    "        # implementacja min_value\n",
    "        pass\n",
    "\n",
    "    best_val, best_move = -math.inf, None\n",
    "    for m in state.get_legal_moves(player):\n",
    "        s2 = copy.deepcopy(state)\n",
    "        s2.apply_move(m)\n",
    "        val = min_value(s2, depth-1, -math.inf, math.inf)\n",
    "        if val > best_val:\n",
    "            best_val, best_move = val, m\n",
    "\n",
    "    return SearchResult(best_move, best_val, stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c8c1d",
   "metadata": {},
   "source": [
    "## 5. Napotkane problemy\n",
    "- Pierwotne heurystyki `material` i `mobility` nie były adekwatne, ponieważ brakowało im sensu - `materiał` jest stały i nie zmienia się w trakcie gry, a `mobilność` licząca możliwą ilość dostępnych ruchów nie tworzyła podziału na ruchy gracza i przeciwnika, co prowadziło, że ich różnica była zawsze równa zero - dodatkowo `mobilność` nie miała do końca sensu jako heurystyka, bo wraz z biegiem gry ilość ruchów będzie się zmniejszać, w związku z tym heurystyka dążyłaby do przedłużania gry, a nie do wygrania\n",
    "- Znalezienie sensownej heurystyki nie było łatwe, ponieważ gra Clobber jest specyficzna i nie ma wielu dostępnych materiałów, a jej zasady pomimo swej prostoty, utrudniają wymyślenie sensownej heurystyki\n",
    "- Parsowanie notacji z formy szachowej do koordynatów w -> `notation_to_index` z wykorzystaniem regexa\n",
    "- Implementacja minimax z alfa-beta była skomplikowana implementacyjnie przez konieczność śledzenia stanu gry i głębokości rekurencji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a4d01b",
   "metadata": {},
   "source": [
    "## 6. Wnioski\n",
    "- Kluczowa jest dobra heurystyka do ograniczenia przestrzeni stanu\n",
    "- Dobra heurystyka jest `kluczowa` do oceny pozycji na niedostatecznie dużej głębokości, ponieważ dla większych plansz nie jest możliwe przeszukiwanie całej przestrzeni stanów\n",
    "- Obsługa terminalnych stanów (+∞/–∞) znacznie polepsza działanie algorytmu, ponieważ pozwala jednoznacznie stwierdzić, kiedy następuje `mat` czyli sytuacja, w której gracz nie może w żaden sposób uratować swojej sytuacji i musi wykonywać ruchy, aż do przegranej\n",
    "- Podział na moduły pozwala na łatwe testowanie i rozwijanie kodu, a także łatwe dodawanie nowych strategii, heurystyk graczy oraz rozpoczynanie różnych starć np. gracz vs gracz albo gracz vs minimax albo minimax vs minimax albo minimax vs random itd. - każdy może grać z każdym"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
