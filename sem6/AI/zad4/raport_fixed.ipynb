{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Sztuczna inteligencja i inżynieria wiedzy \n",
    "### Lista 4\n",
    "##### Aleksander Stepaniuk 272644\n",
    "\n"
   ],
   "id": "b6657a27d7531895"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Kroki realizacji:**  \n",
    "1. Eksploracja danych  \n",
    "2. Przygotowanie danych  \n",
    "3. Trenowanie i strojenie modeli (testowanie klasyfikatorów)\n",
    "4. Ocena wyników klasyfikacji i wnioski\n",
    "\n",
    "**Napotkane trudności:**  \n",
    "- Imbalans klas (najmniej próbek w klasach 3 i 5)\n",
    "- Wysoka wariancja niektórych cech\n",
    "- Konieczność strojenia hiperparametrów dla różnych algorytmów\n"
   ],
   "id": "2e11ed62982630e1"
  },
  {
   "cell_type": "markdown",
   "id": "513cb485b9322904",
   "metadata": {},
   "source": [
    "# ZAD 1. Eksploracja danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T13:55:12.266635Z",
     "start_time": "2025-06-08T13:55:09.809971Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    LB     AC   FM     UC     DL   DS   DP  ASTV  MSTV  ALTV  ...  Width  Min  \\\n",
      "0  120  0.000  0.0  0.000  0.000  0.0  0.0    73   0.5    43  ...     64   62   \n",
      "1  132  0.006  0.0  0.006  0.003  0.0  0.0    17   2.1     0  ...    130   68   \n",
      "2  133  0.003  0.0  0.008  0.003  0.0  0.0    16   2.1     0  ...    130   68   \n",
      "3  134  0.003  0.0  0.008  0.003  0.0  0.0    16   2.4     0  ...    117   53   \n",
      "4  132  0.007  0.0  0.008  0.000  0.0  0.0    16   2.4     0  ...    117   53   \n",
      "\n",
      "   Max  Nmax  Nzeros  Mode  Mean  Median  Variance  Tendency  \n",
      "0  126     2       0   120   137     121        73         1  \n",
      "1  198     6       1   141   136     140        12         0  \n",
      "2  198     5       1   141   135     138        13         0  \n",
      "3  170    11       0   137   134     137        13         1  \n",
      "4  170     9       0   137   136     138        11         1  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "                LB           AC           FM           UC           DL  \\\n",
      "count  2126.000000  2126.000000  2126.000000  2126.000000  2126.000000   \n",
      "mean    133.303857     0.003178     0.009481     0.004366     0.001889   \n",
      "std       9.840844     0.003866     0.046666     0.002946     0.002960   \n",
      "min     106.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%     126.000000     0.000000     0.000000     0.002000     0.000000   \n",
      "50%     133.000000     0.002000     0.000000     0.004000     0.000000   \n",
      "75%     140.000000     0.006000     0.003000     0.007000     0.003000   \n",
      "max     160.000000     0.019000     0.481000     0.015000     0.015000   \n",
      "\n",
      "                DS           DP         ASTV         MSTV        ALTV  ...  \\\n",
      "count  2126.000000  2126.000000  2126.000000  2126.000000  2126.00000  ...   \n",
      "mean      0.000003     0.000159    46.990122     1.332785     9.84666  ...   \n",
      "std       0.000057     0.000590    17.192814     0.883241    18.39688  ...   \n",
      "min       0.000000     0.000000    12.000000     0.200000     0.00000  ...   \n",
      "25%       0.000000     0.000000    32.000000     0.700000     0.00000  ...   \n",
      "50%       0.000000     0.000000    49.000000     1.200000     0.00000  ...   \n",
      "75%       0.000000     0.000000    61.000000     1.700000    11.00000  ...   \n",
      "max       0.001000     0.005000    87.000000     7.000000    91.00000  ...   \n",
      "\n",
      "             Width          Min          Max         Nmax       Nzeros  \\\n",
      "count  2126.000000  2126.000000  2126.000000  2126.000000  2126.000000   \n",
      "mean     70.445908    93.579492   164.025400     4.068203     0.323612   \n",
      "std      38.955693    29.560212    17.944183     2.949386     0.706059   \n",
      "min       3.000000    50.000000   122.000000     0.000000     0.000000   \n",
      "25%      37.000000    67.000000   152.000000     2.000000     0.000000   \n",
      "50%      67.500000    93.000000   162.000000     3.000000     0.000000   \n",
      "75%     100.000000   120.000000   174.000000     6.000000     0.000000   \n",
      "max     180.000000   159.000000   238.000000    18.000000    10.000000   \n",
      "\n",
      "              Mode         Mean       Median     Variance     Tendency  \n",
      "count  2126.000000  2126.000000  2126.000000  2126.000000  2126.000000  \n",
      "mean    137.452023   134.610536   138.090310    18.808090     0.320320  \n",
      "std      16.381289    15.593596    14.466589    28.977636     0.610829  \n",
      "min      60.000000    73.000000    77.000000     0.000000    -1.000000  \n",
      "25%     129.000000   125.000000   129.000000     2.000000     0.000000  \n",
      "50%     139.000000   136.000000   139.000000     7.000000     0.000000  \n",
      "75%     148.000000   145.000000   148.000000    24.000000     1.000000  \n",
      "max     187.000000   182.000000   186.000000   269.000000     1.000000  \n",
      "\n",
      "[8 rows x 21 columns]\n",
      "CLASS\n",
      "1     384\n",
      "2     579\n",
      "3      53\n",
      "4      81\n",
      "5      72\n",
      "6     332\n",
      "7     252\n",
      "8     107\n",
      "9      69\n",
      "10    197\n",
      "Name: count, dtype: int64\n",
      "LB          0\n",
      "AC          0\n",
      "FM          0\n",
      "UC          0\n",
      "DL          0\n",
      "DS          0\n",
      "DP          0\n",
      "ASTV        0\n",
      "MSTV        0\n",
      "ALTV        0\n",
      "MLTV        0\n",
      "Width       0\n",
      "Min         0\n",
      "Max         0\n",
      "Nmax        0\n",
      "Nzeros      0\n",
      "Mode        0\n",
      "Mean        0\n",
      "Median      0\n",
      "Variance    0\n",
      "Tendency    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch datasetu\n",
    "cardiotocography = fetch_ucirepo(id=193)\n",
    "X = cardiotocography.data.features\n",
    "y = cardiotocography.data.targets\n",
    "\n",
    "# 1.1 podgląd pierwszych wierszy\n",
    "print(X.head())\n",
    "\n",
    "# 1.2 podstawowe statystyki opisowe\n",
    "print(X.describe())\n",
    "\n",
    "# 1.3 rozkład klas\n",
    "print(y['CLASS'].value_counts().sort_index())\n",
    "\n",
    "# 1.4 liczba brakujących wartości w każdej kolumnie\n",
    "print(X.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a7d8baae65960",
   "metadata": {},
   "source": [
    "## Uwagi po eksploracji danych (ZAD 1):\n",
    "\n",
    "- Brak braków danych – wszystkie kolumny mają 2126 wartości (w poleceniu jest o brakującym zbiorze, jednak nie został on dostarczony, więc pracujemy nad oryginalnym zbiorem z: https://archive.ics.uci.edu/dataset/193/cardiotocography\n",
    "- Rozkład LB (bazowe FHR czyli fetal heart rate): średnio ~133 bpm, od 106 do 160, odchylenie standardowe w przybliżeniu: 9,8\n",
    "- Zmienność krótkoterminowa (krótkotrwałe wahanie tętna) (ASTV, MSTV) i długoterminowa (ALTV, MLTV) krzywo rozłożone – duży wpływ kilku ekstremów\n",
    "- Histogram FHR: szeroka rozpiętość wariancji (do 269), tendencja przyjmuje wartości –1, 0, 1 (kategoria)\n",
    "- Brak balansu klas: najwięcej próbek w klasie 2 (579) i 1 (384), najmniej w 3 (53) i 5 (72)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a8c0bed49d5fac",
   "metadata": {},
   "source": [
    "# ZAD 2. Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd252bbc1b5245dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T13:55:47.106094Z",
     "start_time": "2025-06-08T13:55:46.236648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw imp: (1488, 21) (638, 21)\n",
      "std: (1488, 21) (638, 21)\n",
      "norm: (1488, 21) (638, 21)\n",
      "pca: (1488, 14) (638, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 2.1 podział na zestaw uczący i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y['CLASS'],\n",
    "    test_size=0.3,\n",
    "    stratify=y['CLASS'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2.2 imputacja braków (mean) – tu zbiór już teoretycznie bez brakujących wartości\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imp = imputer.fit_transform(X_train)\n",
    "X_test_imp = imputer.transform(X_test)\n",
    "\n",
    "# 2.3 różne sposoby przetwarzania:\n",
    "\n",
    "# a) standaryzacja\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train_imp)\n",
    "X_test_std = scaler.transform(X_test_imp)\n",
    "\n",
    "# b) normalizacja do długości wektora = 1\n",
    "normalizer = Normalizer()\n",
    "X_train_norm = normalizer.fit_transform(X_train_imp)\n",
    "X_test_norm = normalizer.transform(X_test_imp)\n",
    "\n",
    "# c) PCA zachowujące 95% wariancji (na danych wystandaryzowanych)\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "# 2.4 kształty macierzy\n",
    "print(\"raw imp:\", X_train_imp.shape, X_test_imp.shape)\n",
    "print(\"std:\",     X_train_std.shape,  X_test_std.shape)\n",
    "print(\"norm:\",    X_train_norm.shape, X_test_norm.shape)\n",
    "print(\"pca:\",     X_train_pca.shape,  X_test_pca.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9de713a0c3659c",
   "metadata": {},
   "source": [
    "## Uwagi po przygotowaniu danych (ZAD 2):\n",
    "- Został utworzony podział na zbiory uczący i testowy z zachowaniem proporcji klas\n",
    "- Imputacja braków nie była konieczna przez kompletny zbiór danych, ale została wykonana dla zasady (i pokazania możliwości)\n",
    "- Standaryzacja i normalizacja zmieniają rozkład cech, co może poprawić wyniki modeli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e3071f2c159e33",
   "metadata": {},
   "source": [
    "# ZAD 3. Modelowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8fef5d8e7f02e45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T14:01:11.961338Z",
     "start_time": "2025-06-08T14:01:11.172026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB: accuracy = 0.586\n",
      "DecisionTreeClassifier: accuracy = 0.82\n",
      "DecisionTreeClassifier: accuracy = 0.779\n",
      "DecisionTreeClassifier: accuracy = 0.809\n",
      "RandomForestClassifier: accuracy = 0.862\n",
      "RandomForestClassifier: accuracy = 0.817\n",
      "SVC: accuracy = 0.807\n",
      "SVC: accuracy = 0.785\n",
      "\n",
      "pruning:\n",
      "DecisionTreeClassifier: accuracy = 0.82\n",
      "DecisionTreeClassifier: accuracy = 0.765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# helper: train & eval\n",
    "def train_eval(model, X_tr, y_tr, X_te, y_te):\n",
    "    model.fit(X_tr, y_tr) # na treningowych się uczy\n",
    "    y_pred = model.predict(X_te) # predykcje robi na testowych\n",
    "    print(f\"{model.__class__.__name__}: accuracy =\",\n",
    "          round(accuracy_score(y_te, y_pred), 3))\n",
    "\n",
    "# 3.1 Gaussian Naive Bayes (naiwny klasyfikator Bayesa)\n",
    "gnb = GaussianNB()\n",
    "train_eval(gnb, X_train_std, y_train, X_test_std, y_test)\n",
    "\n",
    "# 3.2 Decision Tree – 3 zestawy hiperparametrów\n",
    "dt_params = [\n",
    "    {\"random_state\":42}, # stały seed dla powtarzalności wyników\n",
    "    {\"max_depth\":5, \"random_state\":42}, # ograniczenie głębokości drzewa żeby uniknąć przeuczenia (overfitting)\n",
    "    {\"min_samples_split\":10, \"random_state\":42} # wymaga co najmniej 10 próbek aby ograniczyć wzrost drzewa (overfitting)\n",
    "]\n",
    "for params in dt_params:\n",
    "    dt = DecisionTreeClassifier(**params)\n",
    "    train_eval(dt, X_train_std, y_train, X_test_std, y_test)\n",
    "\n",
    "# 3.3 Random Forest (bonusowy)\n",
    "rf_params = [\n",
    "    {\"n_estimators\":100, \"random_state\":42}, # liczba drzew w lesie, 100 to standardowa wartość\n",
    "    {\"n_estimators\":200, \"max_depth\":7, \"random_state\":42} # dodatkowe ograniczenie głębokości każdego drzewa\n",
    "]\n",
    "for params in rf_params:\n",
    "    rf = RandomForestClassifier(**params)\n",
    "    train_eval(rf, X_train_std, y_train, X_test_std, y_test)\n",
    "\n",
    "# 3.4 SVM - Support Vector Machines (bonusowy)\n",
    "svm_models = [\n",
    "    SVC(kernel=\"linear\", random_state=42),\n",
    "    SVC(kernel=\"rbf\", C=1.0, random_state=42)\n",
    "]\n",
    "for svm in svm_models:\n",
    "    train_eval(svm, X_train_std, y_train, X_test_std, y_test)\n",
    "\n",
    "# 3.5 łagodzenie przeuczenia dla drzewa: cost-complexity pruning, porównanie default vs ccp_alpha=0.01\n",
    "# ccp_alpha = 0 -> brak przycinania, większe ryzyko overfittingu\n",
    "# ccp_alpha = 0.01 -> przycinanie gałęzie drzewa które nie poprawiają znacząco jakości podziału aby uprościć drzewo\n",
    "dt_default = DecisionTreeClassifier(random_state=42)\n",
    "dt_pruned  = DecisionTreeClassifier(ccp_alpha=0.01, random_state=42)\n",
    "print(\"\\npruning:\")\n",
    "train_eval(dt_default, X_train_std, y_train, X_test_std, y_test)\n",
    "train_eval(dt_pruned,  X_train_std, y_train, X_test_std, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb15e89ec30605d2",
   "metadata": {},
   "source": [
    "## Uwagi po modelowaniu (ZAD 3):\n",
    "\n",
    "| Model                                           | Accuracy |\n",
    "|-------------------------------------------------|----------|\n",
    "| GaussianNB                                      | 0.586    |\n",
    "| DecisionTree (default)                          | 0.820    |\n",
    "| DecisionTree (max\\_depth=5)                     | 0.779    |\n",
    "| DecisionTree (min\\_samples\\_split=10)           | 0.809    |\n",
    "| RandomForest (n\\_estimators=100)                | 0.862    |\n",
    "| RandomForest (n\\_estimators=200, max\\_depth=7)  | 0.817    |\n",
    "| SVM (kernel=linear)                             | 0.807    |\n",
    "| SVM (kernel=rbf, C=1.0)                         | 0.785    |\n",
    "| DecisionTree (default)                          | 0.820    |\n",
    "| DecisionTree (ccp\\_alpha=0.01, pruned)          | 0.765    |\n",
    "\n",
    "**Wyniki:**  \n",
    "- GaussianNB ma najniższą dokładność (0.586), co sugeruje, że dane nie są dobrze rozdzielone liniowo i wymagają bardziej złożonych modeli (nie pokrywa się z danymi CTG)\n",
    "- DecisionTree bez ograniczeń osiąga 0.820, ale łatwo przeucza się na szumie\n",
    "- DecisionTree z ograniczeniem głębokości (max_depth=5) spada do 0.779, więc ogranicenie głębokości obniża dokładność, drzewo jest zbyt płytkie (underfitting)\n",
    "- DecisionTree z ograniczeniem min_samples_split=10 osiąga 0.809, co jest kompromisem między złożonością a przeuczeniem\n",
    "- Random Forest (100 drzew) to zdecydowanie najlepszy model, osiągający najwyższą dokładność (accuracy 0.862)\n",
    "- Random Forest z 200 drzewami i ograniczeniem głębokości (max_depth=7) osiąga 0.817, co jest nieco gorsze niż 100 drzew bez ograniczeń, może zbyt restrykcyjne ograniczenie głębokości\n",
    "\n",
    "**Podsumowanie:**\n",
    "- GaussianNB nie radzi sobie z nieregularnymi podziałami danych, co jest typowe dla danych CTG\n",
    "- Drzewa pojedyncze potrzebują starannego przycinania albo innych ograniczeń, by unikać under/overfittingu\n",
    "- SVM i Bayes dobrze pokazują, gdzie konieczne jest dalsze strojenie lub zmiana założeń\n",
    "- Random Forest jest najbardziej stabilnym i skutecznym modelem, który dobrze radzi sobie z nieregularnymi podziałami danych\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ZAD 4. Wnioski",
   "id": "668f4133cb4b1c63"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c733b02be3bc94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T14:08:51.577390Z",
     "start_time": "2025-06-08T14:08:51.337371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (macro): 0.858\n",
      "Recall    (macro): 0.796\n",
      "F1-score  (macro): 0.817\n",
      "Confusion matrix:\n",
      " [[ 98   5   1   0   1   1   4   0   0   5]\n",
      " [  6 161   1   2   2   2   0   0   0   0]\n",
      " [  3   2  10   0   0   0   1   0   0   0]\n",
      " [  0   8   0  15   0   1   0   0   0   0]\n",
      " [  6   3   0   0   8   0   0   0   0   4]\n",
      " [  0  10   0   0   0  89   1   0   0   0]\n",
      " [  1   0   0   0   0   6  65   3   0   1]\n",
      " [  0   0   0   0   0   0   2  30   0   0]\n",
      " [  1   0   0   0   0   0   0   0  20   0]\n",
      " [  3   0   0   0   0   0   0   0   2  54]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_std, y_train)\n",
    "y_pred = rf.predict(X_test_std)\n",
    "\n",
    "print(\"Precision (macro):\", round(precision_score(y_test, y_pred, average='macro'), 3))\n",
    "print(\"Recall    (macro):\", round(recall_score   (y_test, y_pred, average='macro'), 3))\n",
    "print(\"F1-score  (macro):\", round(f1_score       (y_test, y_pred, average='macro'), 3))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fce8ab4fd432488",
   "metadata": {},
   "source": [
    "## Interpretacja metryk i macierzy pomyłek (RandomForest n=100)\n",
    "\n",
    "- **Precision (macro) = 0.858**  \n",
    "  Średnio dla wszystkich klas model popełnia raczej niezbyt wiele fałszywych pozytywów (gdy twierdzi, że należy do klasy X, zwykle ma racje)\n",
    "\n",
    "- **Recall (macro) = 0.796**  \n",
    "  Średnio model znajduje prawie 80% wszystkich prawdziwych próbek każdej klasy, niektóre klasy (te rzadsze) mają niższy recall, bo brak danych utrudnia ich wyłapywanie\n",
    "\n",
    "- **F1-score (macro) = 0.817**  \n",
    "  Uśredniona miara łącząca precision i recall – pokazuje dobrą równowagę między nimi.\n",
    "\n",
    "- **Macierz pomyłek**\n",
    "\n",
    "    -   |        | 1  | 2   | 3  | 4  | 5 | 6  | 7  | 8  | 9  | 10 |\n",
    "        |--------|----|-----|----|----|---|----|----|----|----|----|\n",
    "        | **1**  | 98 | 5   | 1  | 0  | 1 | 1  | 4  | 0  | 0  | 5  |\n",
    "        | **2**  | 6  | 161 | 1  | 2  | 2 | 2  | 0  | 0  | 0  | 0  |\n",
    "        | **3**  | 3  | 2   | 10 | 0  | 0 | 0  | 1  | 0  | 0  | 0  |\n",
    "        | **4**  | 0  | 8   | 0  | 15 | 0 | 1  | 0  | 0  | 0  | 0  |\n",
    "        | **5**  | 6  | 3   | 0  | 0  | 8 | 0  | 0  | 0  | 0  | 4  |\n",
    "        | **6**  | 0  | 10  | 0  | 0  | 0 | 89 | 1  | 0  | 0  | 0  |\n",
    "        | **7**  | 1  | 0   | 0  | 0  | 0 | 6  | 65 | 3  | 0  | 1  |\n",
    "        | **8**  | 0  | 0   | 0  | 0  | 0 | 0  | 2  | 30 | 0  | 0  |\n",
    "        | **9**  | 1  | 0   | 0  | 0  | 0 | 0  | 0  | 0  | 20 | 0  |\n",
    "        | **10** | 3  | 0   | 0  | 0  | 0 | 0  | 0  | 0  | 2  | 54 |\n",
    "\n",
    "  - Klasy 1 i 2 (najwięcej próbek) są rozpoznawane bardzo dobrze: mało pomyłek poza swoimi klasami, wysoki recall i precision\n",
    "  - Klasy 3 i 4: tylko po kilkanaście poprawnych detekcji, sporo pomyłek na sąsiednie klasy -> potrzeba więcej danych lub jakiegoś rodzaju oversamplingu\n",
    "  - Klasa 5: sporo pomyłek na klasy 1 i 2, ale też kilka poprawnych detekcji, co sugeruje, że model częściowo rozumie tę klasę\n",
    "  - Klasy 6–10: umiarkowane wyniki, ale klasy 8–10 są już rozpoznawane w większości poprawnie (>70–80%).  \n",
    "\n",
    "**Wnioski:**  \n",
    "- Model świetny dla dominujących klas, ale słabszy dla tych z małą liczbą próbek\n",
    "- Wymaga dalszego strojenia i być może oversamplingu dla klas 3 i 5, które mają najmniej próbek, ewentualnie cost-sensitive learning lub priorytetyzacja recall dla krytycznych wzorców\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
